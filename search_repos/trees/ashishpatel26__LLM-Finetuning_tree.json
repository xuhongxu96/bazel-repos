[
  {
    "path": ".github",
    "mode": "040000",
    "type": "tree",
    "sha": "2434a4d4bb39f9aa2436705c5040440df50121e6",
    "url": "https://api.github.com/repos/ashishpatel26/LLM-Finetuning/git/trees/2434a4d4bb39f9aa2436705c5040440df50121e6"
  },
  {
    "path": "1.Efficiently_train_Large_Language_Models_with_LoRA_and_Hugging_Face.ipynb",
    "mode": "100644",
    "type": "blob",
    "sha": "a94c1f6fc6f40bfd6d086edcb298dffc48eca21b",
    "size": 100767,
    "url": "https://api.github.com/repos/ashishpatel26/LLM-Finetuning/git/blobs/a94c1f6fc6f40bfd6d086edcb298dffc48eca21b"
  },
  {
    "path": "10.MPT_Instruct_30B.ipynb",
    "mode": "100644",
    "type": "blob",
    "sha": "4b981fbd00b009e024d1274eb0210048fab1ded7",
    "size": 395753,
    "url": "https://api.github.com/repos/ashishpatel26/LLM-Finetuning/git/blobs/4b981fbd00b009e024d1274eb0210048fab1ded7"
  },
  {
    "path": "11_RLHF_Training_for_CustomDataset_for_AnyModel.ipynb",
    "mode": "100644",
    "type": "blob",
    "sha": "636a70937dcc7e30c1f52a1cf6890c5d8f7aa8d8",
    "size": 248331,
    "url": "https://api.github.com/repos/ashishpatel26/LLM-Finetuning/git/blobs/636a70937dcc7e30c1f52a1cf6890c5d8f7aa8d8"
  },
  {
    "path": "12_Fine_tuning_Microsoft_Phi_1_5b_on_custom_dataset(dialogstudio).ipynb",
    "mode": "100644",
    "type": "blob",
    "sha": "1987ae447e4ad572a815e107e26b8f9733964c73",
    "size": 350477,
    "url": "https://api.github.com/repos/ashishpatel26/LLM-Finetuning/git/blobs/1987ae447e4ad572a815e107e26b8f9733964c73"
  },
  {
    "path": "13.Fine_tuning_OpenAI_GPT_3_5_turbo.ipynb",
    "mode": "100644",
    "type": "blob",
    "sha": "206f136bc5b193941a11f2d28d44e3f990218ab4",
    "size": 47348,
    "url": "https://api.github.com/repos/ashishpatel26/LLM-Finetuning/git/blobs/206f136bc5b193941a11f2d28d44e3f990218ab4"
  },
  {
    "path": "14.Finetuning_Mistral_7b_Using_AutoTrain.ipynb",
    "mode": "100644",
    "type": "blob",
    "sha": "c93cbef93a1b5dc479717bf2f65517301da95a54",
    "size": 151627,
    "url": "https://api.github.com/repos/ashishpatel26/LLM-Finetuning/git/blobs/c93cbef93a1b5dc479717bf2f65517301da95a54"
  },
  {
    "path": "15.RAG_LangChain.ipynb",
    "mode": "100644",
    "type": "blob",
    "sha": "982b57380b8abf142122caf0a1f44fc81f6901e6",
    "size": 29732,
    "url": "https://api.github.com/repos/ashishpatel26/LLM-Finetuning/git/blobs/982b57380b8abf142122caf0a1f44fc81f6901e6"
  },
  {
    "path": "16.Neo4j_and_LangChain_for_Enhanced_Question_Answering.ipynb",
    "mode": "100644",
    "type": "blob",
    "sha": "3298d67a15477cb92b678eeb7266669122dc5011",
    "size": 13891,
    "url": "https://api.github.com/repos/ashishpatel26/LLM-Finetuning/git/blobs/3298d67a15477cb92b678eeb7266669122dc5011"
  },
  {
    "path": "17.OpenAI_Constructing_Graph_for_Questio_Answer.ipynb",
    "mode": "100644",
    "type": "blob",
    "sha": "1c56be2b7eb09556bcd7d7f3366fe8d7754b3f2e",
    "size": 308956,
    "url": "https://api.github.com/repos/ashishpatel26/LLM-Finetuning/git/blobs/1c56be2b7eb09556bcd7d7f3366fe8d7754b3f2e"
  },
  {
    "path": "18.Convert_Document_to_Knowledge_Graph_Langchain_Openai.ipynb",
    "mode": "100644",
    "type": "blob",
    "sha": "288da97419f05ebe4a48da51e4265768c06b193e",
    "size": 66105,
    "url": "https://api.github.com/repos/ashishpatel26/LLM-Finetuning/git/blobs/288da97419f05ebe4a48da51e4265768c06b193e"
  },
  {
    "path": "19.HQQ_1bit_ipynb.ipynb",
    "mode": "100644",
    "type": "blob",
    "sha": "5592b73ef35e2a655441c4e103a5b6616daf475a",
    "size": 236766,
    "url": "https://api.github.com/repos/ashishpatel26/LLM-Finetuning/git/blobs/5592b73ef35e2a655441c4e103a5b6616daf475a"
  },
  {
    "path": "2.Fine_Tune_Your_Own_Llama_2_Model_in_a_Colab_Notebook.ipynb",
    "mode": "100644",
    "type": "blob",
    "sha": "de0063a971305cc1cdb8939cf6fa6831bc874bed",
    "size": 9541989,
    "url": "https://api.github.com/repos/ashishpatel26/LLM-Finetuning/git/blobs/de0063a971305cc1cdb8939cf6fa6831bc874bed"
  },
  {
    "path": "20.Alpaca_+_Gemma2_9b_Unsloth_2x_faster_finetuning.ipynb",
    "mode": "100644",
    "type": "blob",
    "sha": "8df09cfbaccdc5b16be20d9546c00f2c15aeb292",
    "size": 114734,
    "url": "https://api.github.com/repos/ashishpatel26/LLM-Finetuning/git/blobs/8df09cfbaccdc5b16be20d9546c00f2c15aeb292"
  },
  {
    "path": "21_RAG_Pipeline_Evaluation_Using_MLFLOW_Best_Industry_Practise.ipynb",
    "mode": "100644",
    "type": "blob",
    "sha": "fd54bf776cc13bf6a19493c9f18fc77f3f0d160b",
    "size": 256404,
    "url": "https://api.github.com/repos/ashishpatel26/LLM-Finetuning/git/blobs/fd54bf776cc13bf6a19493c9f18fc77f3f0d160b"
  },
  {
    "path": "22.Evaluate_a_Hugging_Face_LLM_with_mlflow_evaluate.ipynb",
    "mode": "100644",
    "type": "blob",
    "sha": "d4798529c5b66b700cfe19742f2f8944ba989f9f",
    "size": 144384,
    "url": "https://api.github.com/repos/ashishpatel26/LLM-Finetuning/git/blobs/d4798529c5b66b700cfe19742f2f8944ba989f9f"
  },
  {
    "path": "23_CAG_Optimizing_LLMs_with_cache_augmented_generation.ipynb",
    "mode": "100644",
    "type": "blob",
    "sha": "9244159ebb0f3ad90f7a6af66b3069514b328033",
    "size": 564306,
    "url": "https://api.github.com/repos/ashishpatel26/LLM-Finetuning/git/blobs/9244159ebb0f3ad90f7a6af66b3069514b328033"
  },
  {
    "path": "3.Guanaco Chatbot Demo with LLaMA-7B Model.ipynb",
    "mode": "100644",
    "type": "blob",
    "sha": "862043056f6361630354d42eb0858692175cb02a",
    "size": 36346,
    "url": "https://api.github.com/repos/ashishpatel26/LLM-Finetuning/git/blobs/862043056f6361630354d42eb0858692175cb02a"
  },
  {
    "path": "4.PEFT Finetune-Bloom-560m-tagger.ipynb",
    "mode": "100644",
    "type": "blob",
    "sha": "90ab3e310a92de25b673d3a86b60d10e572a0ca6",
    "size": 261754,
    "url": "https://api.github.com/repos/ashishpatel26/LLM-Finetuning/git/blobs/90ab3e310a92de25b673d3a86b60d10e572a0ca6"
  },
  {
    "path": "5.Finetune_Meta_OPT-6-1b_Model_bnb_peft.ipynb",
    "mode": "100644",
    "type": "blob",
    "sha": "a12173708fb110d3bafa02f73d8c5181ee2fd35c",
    "size": 107692,
    "url": "https://api.github.com/repos/ashishpatel26/LLM-Finetuning/git/blobs/a12173708fb110d3bafa02f73d8c5181ee2fd35c"
  },
  {
    "path": "6.Finetune Falcon-7b with BNB Self Supervised Training.ipynb",
    "mode": "100644",
    "type": "blob",
    "sha": "e4824d102edddb23e42ab4403aafba9f661c1429",
    "size": 314465,
    "url": "https://api.github.com/repos/ashishpatel26/LLM-Finetuning/git/blobs/e4824d102edddb23e42ab4403aafba9f661c1429"
  },
  {
    "path": "7.FineTune_LLAMA2_with_QLORA.ipynb",
    "mode": "100644",
    "type": "blob",
    "sha": "4880ee0b703621c85b99e05ee3b97e305f0896b5",
    "size": 473519,
    "url": "https://api.github.com/repos/ashishpatel26/LLM-Finetuning/git/blobs/4880ee0b703621c85b99e05ee3b97e305f0896b5"
  },
  {
    "path": "8.Stable_Vicuna13B_8bit_in_Colab.ipynb",
    "mode": "100644",
    "type": "blob",
    "sha": "1be9705888cd26a48fd0a6a5635189959c95df85",
    "size": 195325,
    "url": "https://api.github.com/repos/ashishpatel26/LLM-Finetuning/git/blobs/1be9705888cd26a48fd0a6a5635189959c95df85"
  },
  {
    "path": "9.GPT-neo-x-20B-bnb_4bit_training.ipynb",
    "mode": "100644",
    "type": "blob",
    "sha": "aef64eb00e6b9064cca8f2bdecd82a00ae39a64b",
    "size": 885117,
    "url": "https://api.github.com/repos/ashishpatel26/LLM-Finetuning/git/blobs/aef64eb00e6b9064cca8f2bdecd82a00ae39a64b"
  },
  {
    "path": "README.md",
    "mode": "100644",
    "type": "blob",
    "sha": "80a3d52005c7571fcdd2b10985cd09ab699e7f9d",
    "size": 14046,
    "url": "https://api.github.com/repos/ashishpatel26/LLM-Finetuning/git/blobs/80a3d52005c7571fcdd2b10985cd09ab699e7f9d"
  }
]