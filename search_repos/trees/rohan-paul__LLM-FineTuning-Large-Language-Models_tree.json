[
  {
    "path": ".gitignore",
    "mode": "100644",
    "type": "blob",
    "sha": "6da452dfda3eefdf9519ffe049d828a3a8294e73",
    "size": 4413,
    "url": "https://api.github.com/repos/rohan-paul/LLM-FineTuning-Large-Language-Models/git/blobs/6da452dfda3eefdf9519ffe049d828a3a8294e73"
  },
  {
    "path": "CodeLLaMA_34B_Conversation_with_Streamlit.py",
    "mode": "100644",
    "type": "blob",
    "sha": "08fb0af0be18e838621976e1c0af5736d1ebb703",
    "size": 8691,
    "url": "https://api.github.com/repos/rohan-paul/LLM-FineTuning-Large-Language-Models/git/blobs/08fb0af0be18e838621976e1c0af5736d1ebb703"
  },
  {
    "path": "Falcon-7B_FineTuning_with_PEFT_and_QLORA.ipynb",
    "mode": "100644",
    "type": "blob",
    "sha": "4ed136cf6760c23163e29662922e74fbc3e64e3b",
    "size": 11607,
    "url": "https://api.github.com/repos/rohan-paul/LLM-FineTuning-Large-Language-Models/git/blobs/4ed136cf6760c23163e29662922e74fbc3e64e3b"
  },
  {
    "path": "FineTuning_phi-1_5_with_PRFT_LoRA.ipynb",
    "mode": "100644",
    "type": "blob",
    "sha": "5db92fb05403f9ba9a744413e1e9a885fb1d76ed",
    "size": 79747,
    "url": "https://api.github.com/repos/rohan-paul/LLM-FineTuning-Large-Language-Models/git/blobs/5db92fb05403f9ba9a744413e1e9a885fb1d76ed"
  },
  {
    "path": "Finetune_codellama-34B-with-QLoRA.ipynb",
    "mode": "100644",
    "type": "blob",
    "sha": "5a44ad7c2c663c2427031e19bcfafa14dbc0edf8",
    "size": 11417,
    "url": "https://api.github.com/repos/rohan-paul/LLM-FineTuning-Large-Language-Models/git/blobs/5a44ad7c2c663c2427031e19bcfafa14dbc0edf8"
  },
  {
    "path": "Finetune_llama_2_GPTQ",
    "mode": "040000",
    "type": "tree",
    "sha": "ddac162148ed1be4f482fc3b26093e6eef47636f",
    "url": "https://api.github.com/repos/rohan-paul/LLM-FineTuning-Large-Language-Models/git/trees/ddac162148ed1be4f482fc3b26093e6eef47636f"
  },
  {
    "path": "Finetune_opt_bnb_peft.ipynb",
    "mode": "100644",
    "type": "blob",
    "sha": "fa4a3f8e8c5b985abee0336998b9635c7d94677b",
    "size": 191222,
    "url": "https://api.github.com/repos/rohan-paul/LLM-FineTuning-Large-Language-Models/git/blobs/fa4a3f8e8c5b985abee0336998b9635c7d94677b"
  },
  {
    "path": "Inference_Yarn-Llama-2-13b-128k_Github.ipynb",
    "mode": "100644",
    "type": "blob",
    "sha": "f09f8f846c1720a9a27c7d863feb179db3848a9b",
    "size": 504292,
    "url": "https://api.github.com/repos/rohan-paul/LLM-FineTuning-Large-Language-Models/git/blobs/f09f8f846c1720a9a27c7d863feb179db3848a9b"
  },
  {
    "path": "Jamba_Finetuning_Colab-Pro.ipynb",
    "mode": "100644",
    "type": "blob",
    "sha": "ec6b07f40544d7f1b5f3e260c0b35118d2104d03",
    "size": 8295,
    "url": "https://api.github.com/repos/rohan-paul/LLM-FineTuning-Large-Language-Models/git/blobs/ec6b07f40544d7f1b5f3e260c0b35118d2104d03"
  },
  {
    "path": "LLM_Techniques_and_utils",
    "mode": "040000",
    "type": "tree",
    "sha": "fc3293c45d7b76b05ccaa9de9c6733be8c00591b",
    "url": "https://api.github.com/repos/rohan-paul/LLM-FineTuning-Large-Language-Models/git/trees/fc3293c45d7b76b05ccaa9de9c6733be8c00591b"
  },
  {
    "path": "LlaMa-2-FineTuning.ipynb",
    "mode": "100644",
    "type": "blob",
    "sha": "6cb6e70ebf3760897e742690e8434e2dca59a4ba",
    "size": 1433,
    "url": "https://api.github.com/repos/rohan-paul/LLM-FineTuning-Large-Language-Models/git/blobs/6cb6e70ebf3760897e742690e8434e2dca59a4ba"
  },
  {
    "path": "Llama-3_Finetuning_on_custom_dataset_with_unsloth.ipynb",
    "mode": "100644",
    "type": "blob",
    "sha": "292aca22d05fa3ef7e9bbeaba004b58fab85263c",
    "size": 137192,
    "url": "https://api.github.com/repos/rohan-paul/LLM-FineTuning-Large-Language-Models/git/blobs/292aca22d05fa3ef7e9bbeaba004b58fab85263c"
  },
  {
    "path": "Llama_3_Finetuning_ORPO_with_Unsloth.ipynb",
    "mode": "100644",
    "type": "blob",
    "sha": "fe651575ebc206e187b5d09c7571c1d69dbbebc4",
    "size": 162485,
    "url": "https://api.github.com/repos/rohan-paul/LLM-FineTuning-Large-Language-Models/git/blobs/fe651575ebc206e187b5d09c7571c1d69dbbebc4"
  },
  {
    "path": "Local-Inferencing_LlaMa-2.ipynb",
    "mode": "100644",
    "type": "blob",
    "sha": "b5d867356a9971be8c80fabbf40c70d9fa57f01b",
    "size": 56532,
    "url": "https://api.github.com/repos/rohan-paul/LLM-FineTuning-Large-Language-Models/git/blobs/b5d867356a9971be8c80fabbf40c70d9fa57f01b"
  },
  {
    "path": "Mistral-7B-Inferencing.ipynb",
    "mode": "100644",
    "type": "blob",
    "sha": "3c448c48f7fd5ccd104da1b8da386f37b77c2866",
    "size": 3307,
    "url": "https://api.github.com/repos/rohan-paul/LLM-FineTuning-Large-Language-Models/git/blobs/3c448c48f7fd5ccd104da1b8da386f37b77c2866"
  },
  {
    "path": "Mistral_7B_Instruct_GPTQ_finetune.ipynb",
    "mode": "100644",
    "type": "blob",
    "sha": "6fd36e6ef409b0079bc2be09c9f28711080c84a3",
    "size": 33081,
    "url": "https://api.github.com/repos/rohan-paul/LLM-FineTuning-Large-Language-Models/git/blobs/6fd36e6ef409b0079bc2be09c9f28711080c84a3"
  },
  {
    "path": "Mistral_7b_FineTuning_with_DPO_Direct_Preference_Optimization.ipynb",
    "mode": "100644",
    "type": "blob",
    "sha": "b3a7e4d5c0f0f999b7b91f763829d65a29ee9298",
    "size": 28670,
    "url": "https://api.github.com/repos/rohan-paul/LLM-FineTuning-Large-Language-Models/git/blobs/b3a7e4d5c0f0f999b7b91f763829d65a29ee9298"
  },
  {
    "path": "Mistral_FineTuning_with_PEFT_and_QLORA.ipynb",
    "mode": "100644",
    "type": "blob",
    "sha": "859e2bfc82c7ef5c98070d672d2e11d34d60e113",
    "size": 18200,
    "url": "https://api.github.com/repos/rohan-paul/LLM-FineTuning-Large-Language-Models/git/blobs/859e2bfc82c7ef5c98070d672d2e11d34d60e113"
  },
  {
    "path": "Mixtral_Chatbot_with_Gradio",
    "mode": "040000",
    "type": "tree",
    "sha": "980dd84be9d2a7bbc6b21e41380dd83d0180ea48",
    "url": "https://api.github.com/repos/rohan-paul/LLM-FineTuning-Large-Language-Models/git/trees/980dd84be9d2a7bbc6b21e41380dd83d0180ea48"
  },
  {
    "path": "Nous-Hermes-2-Yi-34B-GGUF_in_Kaggle_free_GPU_with_llama_cpp.ipynb",
    "mode": "100644",
    "type": "blob",
    "sha": "a891590e59f1927a2461577bd1aebafcbc936021",
    "size": 1712,
    "url": "https://api.github.com/repos/rohan-paul/LLM-FineTuning-Large-Language-Models/git/blobs/a891590e59f1927a2461577bd1aebafcbc936021"
  },
  {
    "path": "Other-Language_Models_BERT_related",
    "mode": "040000",
    "type": "tree",
    "sha": "2fb21a77384bddafa09607f80e24e8bd3df41913",
    "url": "https://api.github.com/repos/rohan-paul/LLM-FineTuning-Large-Language-Models/git/trees/2fb21a77384bddafa09607f80e24e8bd3df41913"
  },
  {
    "path": "Quantize_with_HF_transformers",
    "mode": "040000",
    "type": "tree",
    "sha": "d449f2248b272542f592d31f4f8dbee479e122ce",
    "url": "https://api.github.com/repos/rohan-paul/LLM-FineTuning-Large-Language-Models/git/trees/d449f2248b272542f592d31f4f8dbee479e122ce"
  },
  {
    "path": "README.md",
    "mode": "100644",
    "type": "blob",
    "sha": "762a48e0ea88d061182dca6adb063148044dc401",
    "size": 23465,
    "url": "https://api.github.com/repos/rohan-paul/LLM-FineTuning-Large-Language-Models/git/blobs/762a48e0ea88d061182dca6adb063148044dc401"
  },
  {
    "path": "TinyLlama_with_Unsloth_and_RoPE_Scaling_dolly-15k.ipynb",
    "mode": "100644",
    "type": "blob",
    "sha": "40f1d7f318039d1c21e3a57c70b3822ea91cd9b5",
    "size": 170983,
    "url": "https://api.github.com/repos/rohan-paul/LLM-FineTuning-Large-Language-Models/git/blobs/40f1d7f318039d1c21e3a57c70b3822ea91cd9b5"
  },
  {
    "path": "TogetherAI_API_with_LangChain.ipynb",
    "mode": "100644",
    "type": "blob",
    "sha": "f309d7ce36782471abc91131ccc6ad6df95a1757",
    "size": 5417,
    "url": "https://api.github.com/repos/rohan-paul/LLM-FineTuning-Large-Language-Models/git/blobs/f309d7ce36782471abc91131ccc6ad6df95a1757"
  },
  {
    "path": "Web_scraping_with_Large_Language_Models_LLM_AnthropicAI_LangChainAI.ipynb",
    "mode": "100644",
    "type": "blob",
    "sha": "4c39476b078bf329fb240e03c8ff7efe63e3ccea",
    "size": 3556,
    "url": "https://api.github.com/repos/rohan-paul/LLM-FineTuning-Large-Language-Models/git/blobs/4c39476b078bf329fb240e03c8ff7efe63e3ccea"
  },
  {
    "path": "assets",
    "mode": "040000",
    "type": "tree",
    "sha": "4c7b75a5a7ce2fffef3a6aebb33d6d7b4fbf150b",
    "url": "https://api.github.com/repos/rohan-paul/LLM-FineTuning-Large-Language-Models/git/trees/4c7b75a5a7ce2fffef3a6aebb33d6d7b4fbf150b"
  },
  {
    "path": "enable_json_mode.ipynb",
    "mode": "100644",
    "type": "blob",
    "sha": "424ca0905d717ae0224c2ca3465db11b8d215a91",
    "size": 2828,
    "url": "https://api.github.com/repos/rohan-paul/LLM-FineTuning-Large-Language-Models/git/blobs/424ca0905d717ae0224c2ca3465db11b8d215a91"
  },
  {
    "path": "gemma-2b_ORPO_FineTuning_full_precision",
    "mode": "040000",
    "type": "tree",
    "sha": "8913b6521f9e89c2df083f5ebca4bf306ec34485",
    "url": "https://api.github.com/repos/rohan-paul/LLM-FineTuning-Large-Language-Models/git/trees/8913b6521f9e89c2df083f5ebca4bf306ec34485"
  },
  {
    "path": "layered_inference_with_airllm_70B_LLM_Inference_on_a_Single_4GB_GPU.ipynb",
    "mode": "100644",
    "type": "blob",
    "sha": "ad7ec4f6062b1efa4e71d366dbe1316269080a9b",
    "size": 1489,
    "url": "https://api.github.com/repos/rohan-paul/LLM-FineTuning-Large-Language-Models/git/blobs/ad7ec4f6062b1efa4e71d366dbe1316269080a9b"
  },
  {
    "path": "tinyllama_fine-tuning_Taylor_Swift.ipynb",
    "mode": "100644",
    "type": "blob",
    "sha": "d250a56bd8a2aab0868aa2623698aceebc21d221",
    "size": 104178,
    "url": "https://api.github.com/repos/rohan-paul/LLM-FineTuning-Large-Language-Models/git/blobs/d250a56bd8a2aab0868aa2623698aceebc21d221"
  },
  {
    "path": "togetherai-api-with_Mixtral.ipynb",
    "mode": "100644",
    "type": "blob",
    "sha": "39b0a366117375a39f8f6173f7abd0cd110bcfd2",
    "size": 6591,
    "url": "https://api.github.com/repos/rohan-paul/LLM-FineTuning-Large-Language-Models/git/blobs/39b0a366117375a39f8f6173f7abd0cd110bcfd2"
  }
]