{
  "id": 617290848,
  "node_id": "R_kgDOJMscYA",
  "name": "gpt-tokenizer",
  "full_name": "niieani/gpt-tokenizer",
  "private": false,
  "owner": {
    "login": "niieani",
    "id": 563469,
    "node_id": "MDQ6VXNlcjU2MzQ2OQ==",
    "avatar_url": "https://avatars.githubusercontent.com/u/563469?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/niieani",
    "html_url": "https://github.com/niieani",
    "followers_url": "https://api.github.com/users/niieani/followers",
    "following_url": "https://api.github.com/users/niieani/following{/other_user}",
    "gists_url": "https://api.github.com/users/niieani/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/niieani/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/niieani/subscriptions",
    "organizations_url": "https://api.github.com/users/niieani/orgs",
    "repos_url": "https://api.github.com/users/niieani/repos",
    "events_url": "https://api.github.com/users/niieani/events{/privacy}",
    "received_events_url": "https://api.github.com/users/niieani/received_events",
    "type": "User",
    "user_view_type": "public",
    "site_admin": false
  },
  "html_url": "https://github.com/niieani/gpt-tokenizer",
  "description": "The fastest JavaScript BPE Tokenizer Encoder Decoder for OpenAI's GPT models (o1, o3, o4, gpt-4o, gpt-4, etc.). Port of OpenAI's tiktoken with additional features.",
  "fork": false,
  "url": "https://api.github.com/repos/niieani/gpt-tokenizer",
  "forks_url": "https://api.github.com/repos/niieani/gpt-tokenizer/forks",
  "keys_url": "https://api.github.com/repos/niieani/gpt-tokenizer/keys{/key_id}",
  "collaborators_url": "https://api.github.com/repos/niieani/gpt-tokenizer/collaborators{/collaborator}",
  "teams_url": "https://api.github.com/repos/niieani/gpt-tokenizer/teams",
  "hooks_url": "https://api.github.com/repos/niieani/gpt-tokenizer/hooks",
  "issue_events_url": "https://api.github.com/repos/niieani/gpt-tokenizer/issues/events{/number}",
  "events_url": "https://api.github.com/repos/niieani/gpt-tokenizer/events",
  "assignees_url": "https://api.github.com/repos/niieani/gpt-tokenizer/assignees{/user}",
  "branches_url": "https://api.github.com/repos/niieani/gpt-tokenizer/branches{/branch}",
  "tags_url": "https://api.github.com/repos/niieani/gpt-tokenizer/tags",
  "blobs_url": "https://api.github.com/repos/niieani/gpt-tokenizer/git/blobs{/sha}",
  "git_tags_url": "https://api.github.com/repos/niieani/gpt-tokenizer/git/tags{/sha}",
  "git_refs_url": "https://api.github.com/repos/niieani/gpt-tokenizer/git/refs{/sha}",
  "trees_url": "https://api.github.com/repos/niieani/gpt-tokenizer/git/trees{/sha}",
  "statuses_url": "https://api.github.com/repos/niieani/gpt-tokenizer/statuses/{sha}",
  "languages_url": "https://api.github.com/repos/niieani/gpt-tokenizer/languages",
  "stargazers_url": "https://api.github.com/repos/niieani/gpt-tokenizer/stargazers",
  "contributors_url": "https://api.github.com/repos/niieani/gpt-tokenizer/contributors",
  "subscribers_url": "https://api.github.com/repos/niieani/gpt-tokenizer/subscribers",
  "subscription_url": "https://api.github.com/repos/niieani/gpt-tokenizer/subscription",
  "commits_url": "https://api.github.com/repos/niieani/gpt-tokenizer/commits{/sha}",
  "git_commits_url": "https://api.github.com/repos/niieani/gpt-tokenizer/git/commits{/sha}",
  "comments_url": "https://api.github.com/repos/niieani/gpt-tokenizer/comments{/number}",
  "issue_comment_url": "https://api.github.com/repos/niieani/gpt-tokenizer/issues/comments{/number}",
  "contents_url": "https://api.github.com/repos/niieani/gpt-tokenizer/contents/{+path}",
  "compare_url": "https://api.github.com/repos/niieani/gpt-tokenizer/compare/{base}...{head}",
  "merges_url": "https://api.github.com/repos/niieani/gpt-tokenizer/merges",
  "archive_url": "https://api.github.com/repos/niieani/gpt-tokenizer/{archive_format}{/ref}",
  "downloads_url": "https://api.github.com/repos/niieani/gpt-tokenizer/downloads",
  "issues_url": "https://api.github.com/repos/niieani/gpt-tokenizer/issues{/number}",
  "pulls_url": "https://api.github.com/repos/niieani/gpt-tokenizer/pulls{/number}",
  "milestones_url": "https://api.github.com/repos/niieani/gpt-tokenizer/milestones{/number}",
  "notifications_url": "https://api.github.com/repos/niieani/gpt-tokenizer/notifications{?since,all,participating}",
  "labels_url": "https://api.github.com/repos/niieani/gpt-tokenizer/labels{/name}",
  "releases_url": "https://api.github.com/repos/niieani/gpt-tokenizer/releases{/id}",
  "deployments_url": "https://api.github.com/repos/niieani/gpt-tokenizer/deployments",
  "created_at": "2023-03-22T04:32:09Z",
  "updated_at": "2025-08-04T22:57:59Z",
  "pushed_at": "2025-06-13T05:03:57Z",
  "git_url": "git://github.com/niieani/gpt-tokenizer.git",
  "ssh_url": "git@github.com:niieani/gpt-tokenizer.git",
  "clone_url": "https://github.com/niieani/gpt-tokenizer.git",
  "svn_url": "https://github.com/niieani/gpt-tokenizer",
  "homepage": "https://gpt-tokenizer.dev",
  "size": 15156,
  "stargazers_count": 598,
  "watchers_count": 598,
  "language": "TypeScript",
  "has_issues": true,
  "has_projects": true,
  "has_downloads": true,
  "has_wiki": false,
  "has_pages": false,
  "has_discussions": true,
  "forks_count": 44,
  "mirror_url": null,
  "archived": false,
  "disabled": false,
  "open_issues_count": 5,
  "license": {
    "key": "mit",
    "name": "MIT License",
    "spdx_id": "MIT",
    "url": "https://api.github.com/licenses/mit",
    "node_id": "MDc6TGljZW5zZTEz"
  },
  "allow_forking": true,
  "is_template": false,
  "web_commit_signoff_required": false,
  "topics": [
    "bpe",
    "decoder",
    "encoder",
    "gpt-2",
    "gpt-3",
    "gpt-4",
    "gpt-4o",
    "gpt-o1",
    "machine-learning",
    "openai",
    "tokenizer"
  ],
  "visibility": "public",
  "forks": 44,
  "open_issues": 5,
  "watchers": 598,
  "default_branch": "main",
  "permissions": {
    "admin": false,
    "maintain": false,
    "push": false,
    "triage": false,
    "pull": true
  },
  "score": 1.0
}